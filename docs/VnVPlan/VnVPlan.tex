\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Project Title: System Verification and Validation Plan for \progname{}} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\\
\wss{The intention of the VnV plan is to increase confidence in the software.
However, this does not mean listing every verification and validation technique
that has ever been devised.  The VnV plan should also be a \textbf{feasible}
plan. Execution of the plan should be possible with the time and team available.
If the full plan cannot be completed during the time available, it can either be
modified to ``fake it'', or a better solution is to add a section describing
what work has been completed and what work is still planned for the future.}

\wss{The VnV plan is typically started after the requirements stage, but before
the design stage.  This means that the sections related to unit testing cannot
initially be completed.  The sections will be filled in after the design stage
is complete.  the final version of the VnV plan should have all sections filled
in.}

\newpage

\tableofcontents

\listoftables
\wss{Remove this section if it isn't needed}

\listoffigures
\wss{Remove this section if it isn't needed}

\newpage

\section{Symbols, Abbreviations, and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations, or acronyms --- you can simply reference the SRS
  \citep{SRS} tables, if appropriate}

\wss{Remove this section if it isn't needed}

\newpage

\pagenumbering{arabic}

This document ... \wss{provide an introductory blurb and roadmap of the
  Verification and Validation plan}

\section{General Information}

\subsection{Summary}

\wss{Say what software is being tested.  Give its name and a brief overview of
  its general functions.}

\subsection{Objectives}

\wss{State what is intended to be accomplished.  The objective will be around
  the qualities that are most important for your project.  You might have
  something like: ``build confidence in the software correctness,''
  ``demonstrate adequate usability.'' etc.  You won't list all of the qualities,
  just those that are most important.}

\wss{You should also list the objectives that are out of scope.  You don't have 
the resources to do everything, so what will you be leaving out.  For instance, 
if you are not going to verify the quality of usability, state this.  It is also 
worthwhile to justify why the objectives are left out.}

\wss{The objectives are important because they highlight that you are aware of 
limitations in your resources for verification and validation.  You can't do everything, 
so what are you going to prioritize?  As an example, if your system depends on an 
external library, you can explicitly state that you will assume that external library 
has already been verified by its implementation team.}

\subsection{Relevant Documentation}

\wss{Reference relevant documentation.  This will definitely include your SRS
  and your other project documents (design documents, like MG, MIS, etc).  You
  can include these even before they are written, since by the time the project
  is done, they will be written.}

\citet{SRS}

\wss{Don't just list the other documents.  You should explain why they are relevant and 
how they relate to your VnV efforts.}

\section{Plan}

\subsection{Verification and Validation Team}

Although all team members will be responsible for writing/understanding all aspects of the project's test suite, each member will have a particular specific role within the area.

\begin{table}[h]
  \centering
  \begin{tabular}{|l|l|}
    \hline
    \textbf{Team Member} & \textbf{Project Verification Role} \\
    \hline
    Daniel Akselrod & Test Automation Expert: Responsible for all CD/CI testing \\
    \hline
    Jonathan Avraham & Test Designer/Case Writer: Create test cases \\
    \hline
    Sam McDonald & Test Strategist/Planner: Defines overall testing strategy \\
    \hline
    Sophie Fillion & Test Result Analysis: Analyze failing tests and create new issues \\
    \hline
  \end{tabular}
  \caption{Roles of the Verification and Validation Team}
  \label{tab:verification_validation_team}
\end{table}

\subsection{SRS Verification Plan}

\subsubsection{Objective of the Verification Plan}
The objective of this SRS verification plan is to ensure that SweatSmarts software complies with both the functional and non-functional requirements specified in the accompanying Software Requirements Specification document. This comprehensive verification process aims to ensure that the software is not only capable of performing its intended functions but also excels in terms of usability, performance, security, and compliance with industry standards. Specifically, the test plan should satisfy the following: Functional and nonfunctional requirement compliances, safety, user experiences and satisfaction, and the correct testing tools.

\subsubsection{Scope}
This test plan and verification will cover all of the functional and nonfunctional requirements that have been written in the SRS. This verification plan will describe what will be covered when undergoing verifications of requirements, the test cases and test criteria, the schedule of verification defining the amount of time it will take, the roles and responsibilities, and the acceptance criteria of each test.

\subsubsection{Verification Methods/Tests}
Testing is crucial in the Software development Life Cycle as it allows developers to find bugs within the system, can help identify whether certain components within the system work as anticipated and if it meets the needs of its stakeholders. Here are a few testing methods that will aid in the verification process:

\begin{itemize}
  \item \textbf{Functional Testing:} Functional tests will be conducted to verify the functionality of the system. The purpose is to test the functional requirements of the system as described in the SRS.
  \item \textbf{Unit testing:} Unit tests verify individual components (units) of the software where they are isolated from the rest. The purpose is to create unit tests for specific functions or modules to verify that they behave correctly.
  \item \textbf{Manual and Automated Testing:} Manual testing are tests that are conducted by people without test scripts. Automated testing is when tests are executed automatically via testing tools and frameworks such as Jest or XUnit.
  \item \textbf{Static and Dynamic Testing:} Static testing means to examine the code without actually executing it to look for coding style and quality. Dynamic testing is used to verify the code by executing it and observing its behavior during runtime.
\end{itemize}

\subsubsection{Test Cases and Criteria}
In this section, we write detailed test cases for each requirement in the SRS, including both the functional and non-functional requirements. Each case will include the following:

\begin{itemize}
  \item \textbf{The input data}
  \item \textbf{The expected output data}
  \item \textbf{The criteria for a pass/fail test}
  \item \textbf{The tools used to test the requirement}
\end{itemize}

\subsubsection{Schedule and Result}
The verification of the SRS will take place from [start date] to [end date]. The software will be considered verified once all test cases pass for all non-functional and functional requirements.

\subsection{Design Verification Plan}

\subsubsection{Architecture Review}
Validate the system design for scalability and robustness before development begins.

\subsubsection{UI/UX Testing}
Assess the interface and user flow for intuitiveness through user feedback and expert review.

\subsubsection{Algorithm Efficiency}
Confirm AI algorithm accuracy and backend efficiency through iterative testing with real-world data.

\subsubsection{Security Checks}
Evaluate application security features against industry best practices and standards.

\subsection{Verification and Validation Plan Verification Plan}

\subsubsection{Plan Review}
Implement periodic peer reviews, with a focus on comprehensive coverage and clarity.

\subsubsection{Mutation Testing}
Use mutation testing to assess the plan's ability to detect faults and improve test cases.

\subsubsection{Checklist Creation}
Develop checklists to standardize review processes and ensure all critical aspects of the plan are evaluated.

\subsection{Implementation Verification Plan}

\noindent \textbf{Objective:} Ensure the integrity and correctness of the implementation through static verification techniques.

\subsubsection{Code Walk-Throughs}
\begin{itemize}
  \item Schedule regular sessions where developers present their code to the team for examination.
  \item Focus on logical flow, adherence to design specifications, and potential logic errors.
  \item Document insights and action items for improvement.
\end{itemize}

\subsubsection{Code Inspection}
\begin{itemize}
  \item Formalize a code inspection process with checklists tailored to project standards and best practices.
  \item Assign roles for moderator, author, scribe, and reviewers to structure the inspection.
  \item Utilize inspection outcomes to refine coding guidelines and improve code quality.
\end{itemize}

\subsubsection{Static Analyzers}
\begin{itemize}
  \item Integrate automated static analysis tools into the development workflow.
  \item Configure tools to flag coding standards violations, potential bugs, security vulnerabilities, and performance issues.
  \item Review and address flagged issues in a timely manner, prioritizing based on severity.
\end{itemize}

\subsubsection{Automated Code Reviews}
\begin{itemize}
  \item Set up custom rules and linting based on the projectâ€™s coding standards.
\end{itemize}

\subsubsection{Continuous Integration (CI) Checks}
\begin{itemize}
  \item Enforce static verification checks within the CI pipeline.
  \item Prevent merging of code changes that fail to meet the defined static analysis criteria.
\end{itemize}

\subsection{Automated Testing and Verification Tools}

\subsubsection{Unit Testing}
\begin{itemize}
  \item With React Native, we employ Jest to test our application's components, functions, and hooks thoroughly. This framework facilitates simulation of user interactions and verification of component behavior.
  \item XUnit serves as the backbone for testing our .NET Core Web API. It will ensure that all units of application logic are tested for expected outcomes.
\end{itemize}

\subsubsection{Static Code Analysis}
\begin{itemize}
  \item ESLint and Prettier will be used in tandem to maintain code quality and consistency in our React Native codebase, ensuring adherence to our defined coding standards.
  \item dotnet format and other .NET analyzers will scrutinize our backend code, enforcing the .NET Core's conventions and coding practices.
\end{itemize}

\subsubsection{Continuous Integration (CI)}
\begin{itemize}
  \item We will use GitHub Actions to automate our continuous integration workflow. On every push and pull request, GitHub Actions will trigger the build and test processes for both the mobile and web API components, ensuring that changes do not introduce regressions or break existing functionality.
\end{itemize}

\subsubsection{Code Coverage}
\begin{itemize}
  \item Integrated code coverage tools within Jest for React Native and XUnit for .NET Core will provide insights into the portions of our codebase exercised by unit tests. Our goal is to maintain a high level of code coverage, correlating with fewer production bugs.
\end{itemize}

\subsection{Software Validation Plan}

\subsubsection{Objective}
The objective of this SRS validation plan is to ensure that the software meets user needs and expectations, delivers its appropriate functionality to its users, and runs properly in its environment. It is essentially the process of checking whether or not customers' requirements are being met.

\subsubsection{Scope}
This validation plan will typically occur after the development phase as its intent is to ensure the satisfaction of user requirements and is ready in the environment that it is being used. Validation checks the software against the actual user and system requirements, ensuring that it provides the intended functionality and value. The validation plan will include the following: Validation methods for testing, test input and criteria, as well as a schedule for the validation aspect of the development cycle.

\subsubsection{Validation methods}
Usability testing is essential for assessing the user experience and the effectiveness of a product. It is complemented by regression testing, which is crucial for ensuring that new updates or changes to the software don't introduce fresh issues. In tandem, performance testing evaluates the system's response time and resource usage to ensure it operates efficiently. Security testing is another vital component, aimed at identifying and mitigating any vulnerabilities in the code. Lastly, functional testing is carried out to verify that the system operates as intended by executing the code and checking the functionality. Together, these different types of testing form a comprehensive approach to ensuring the quality and reliability of software products.

\subsubsection{Test Cases and Criteria}
In this section, we write detailed test cases for each requirement in the SRS including both the functional and non-functional requirements. Each case will include the input data, the expected output data, the criteria for a passed/failed test, and the tools used to test the requirement.

\subsubsection{Scheduling and result}
It is important to note that the validation plan aims for the end product that is ready to be deployed. Therefore, the validation is scheduled to start from [start date] to [end date]. The software will be considered validated once it passes all validation tests successfully and meets user expectations.

\section{System Test Description}
	
\subsection{Tests for Functional Requirements}

\wss{Subsets of the tests may be in related, so this section is divided into
  different areas.  If there are no identifiable subsets for the tests, this
  level of document structure can be removed.}

\wss{Include a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good here.}

\subsubsection{Area of Testing1}

\wss{It would be nice to have a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good here.  If a section
  covers tests for input constraints, you should reference the data constraints
  table in the SRS.}
		
\paragraph{Title for Test}

\begin{enumerate}

\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
					
\item{test-id2\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}

How test will be performed: 

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Tests for Nonfunctional Requirements}

\wss{The nonfunctional requirements for accuracy will likely just reference the
  appropriate functional tests from above.  The test cases should mention
  reporting the relative error for these tests.  Not all projects will
  necessarily have nonfunctional requirements related to accuracy}

\wss{Tests related to usability could include conducting a usability test and
  survey.  The survey will be in the Appendix.}

\wss{Static tests, review, inspections, and walkthroughs, will not follow the
format for the tests given below.}

\subsubsection{Area of Testing1}
		
\paragraph{Title for Test}

\begin{enumerate}

\item{test-id1\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input/Condition: 
					
Output/Result: 
					
How test will be performed: 
					
\item{test-id2\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Traceability Between Test Cases and Requirements}

\wss{Provide a table that shows which test cases are supporting which
  requirements.}

\section{Unit Test Description}

This section is to be completed when the MIS (detailed design document) is completed.

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

\wss{This is a section that would be appropriate for some projects.}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\newpage{}
\section*{Appendix --- Reflection}

\wss{This section is not required for CAS 741}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\begin{enumerate}
  \item What knowledge and skills will the team collectively need to acquire to
  successfully complete the verification and validation of your project?
  Examples of possible knowledge and skills include dynamic testing knowledge,
  static testing knowledge, specific tool usage etc.  You should look to
  identify at least one item for each team member.
  \item For each of the knowledge areas and skills identified in the previous
  question, what are at least two approaches to acquiring the knowledge or
  mastering the skill?  Of the identified approaches, which will each team
  member pursue, and why did they make this choice?
\end{enumerate}

\end{document}